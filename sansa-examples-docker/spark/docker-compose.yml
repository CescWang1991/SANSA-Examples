version: '2' 
services:
 namenode:
    image: bde2020/hadoop-namenode:1.0.0
    hostname: namenode
    container_name: namenode
    domainname: hadoop
    networks:
      - hadoop
    volumes:
      - ./data/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
      - INIT_DAEMON_STEP=setup_hdfs
      - VIRTUAL_HOST=hdfs.demo.big-data-europe.local
    env_file:
      - ./config/hadoop/hadoop.env
    ports:
      - "50070:50070"
      - "8020:8020"
 datanode1:
    image: bde2020/hadoop-datanode:1.0.0
    hostname: datanode1
    container_name: datanode1
    domainname: hadoop
    networks:
      - hadoop
    volumes:
      - ./data/datanode1:/hadoop/dfs/data
    env_file:
      - ./config/hadoop/hadoop.env

 datanode2:
    image: bde2020/hadoop-datanode:1.0.0
    hostname: datanode2
    container_name: datanode2
    domainname: hadoop
    networks: 
      - hadoop
    volumes:
      - ./data/datanode2:/hadoop/dfs/data
    env_file:
      - ./config/hadoop/hadoop.env

 filebrowser:
    image: bde2020/hdfs-filebrowser:3.9
    hostname: filebrowser
    container_name: filebrowser
    domainname: hadoop
    networks:
      - hadoop
    environment:
      - NAMENODE_HOST=namenode
      - VIRTUAL_HOST=hue.demo.big-data-europe.local
      - VIRTUAL_PORT=8088
      - django_debug_mode=false
#    ports:
#      - "8088:8088"

 spark-master:
   image: bde2020/spark-master:1.5.1-hadoop2.6
   hostname: spark-master
   container_name: spark-master
   domainname: hadoop
   networks:
     - hadoop
   environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - VIRTUAL_HOST=spark-master.demo.big-data-europe.local
      - VIRTUAL_PORT=8080
   env_file:
      - ./config/hadoop/hadoop.env

 spark-worker:
   image: bde2020/spark-worker:1.5.1-hadoop2.6
   hostname: spark-worker
   container_name: spark-worker
   domainname: hadoop
   networks: 
     - hadoop
   environment:
     - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
     - VIRTUAL_HOST=flink-worker.demo.big-data-europe.local
     - VIRTUAL_PORT=8081 
   env_file:
     - ./config/hadoop/hadoop.env
   links:
      - "spark-master"

 sansa-examples:
  build: .
  hostname: sansa-examples
  container_name: sansa-examples
  domainname: hadoop
  networks:
    - hadoop
  environment:
      - HDFS_URL=hdfs://namenode:8020
  env_file:
    - ./config/hadoop/hadoop.env
  links:
   - "spark-master"

 integratorui:
   image: bde2020/integrator-ui:latest
   hostname: integratorui
   container_name: integratorui
   domainname: hadoop
   networks:
     - hadoop
   volumes:
      - ./config/integrator:/app/config
   environment:
      - VIRTUAL_HOST=demo.big-data-europe.local

 csswrapper:
    build: ./csswrapper/
    hostname: csswrapper
    container_name: csswrapper
    domainname: hadoop
    networks:
      - hadoop
    ports:
      - 80:80
    links:
      - namenode:namenode
      - filebrowser:filebrowser
      - spark-master:spark-master
      - spark-worker:spark-worker
      - integratorui:integratorui
    depends_on:
      - namenode
      - filebrowser
      - spark-master
      - spark-worker
      - integratorui

 identifier:
  image: semtech/mu-identifier:1.0.0
  hostname: identifier
  container_name: identifier
  domainname: hadoop
  networks:
   - hadoop

 dispatcher:
  image: semtech/mu-dispatcher:1.0.1
  hostname: dispatcher
  container_name: dispatcher
  domainname: hadoop
  networks:
    - hadoop
  volumes:
    - ./config:/config

 pipeline:
  image: bde2020/mu-pipeline-service:0.1.0
  hostname: pipeline
  container_name: pipeline
  domainname: hadoop
  networks:
    - hadoop

 initdaemon:
  image: bde2020/mu-init-daemon-service:0.1.0
  hostname: initdaemon
  container_name: initdaemon
  domainname: hadoop
  networks:
    - hadoop

networks:
  hadoop:
    external: true
